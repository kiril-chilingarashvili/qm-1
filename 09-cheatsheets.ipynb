{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08871084-23e1-4715-b298-e2666b05e6a8",
   "metadata": {},
   "source": [
    "# Lecture 9: Observables, Hermitian operators, measurement and uncertainty, Particle on a circle, Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690ba73b-76a3-49a1-87d8-4ae2634a618e",
   "metadata": {},
   "source": [
    "## 9.1 Observables and Hermitian operators\n",
    "\n",
    "### Let’s begin by recalling the definition of a Hermitian operator. The operator $\\hat{Q}$ is Hermitian if for the class of wavefunctions $\\Psi$ we work with,\n",
    "## $$ \\int \\mathop{dx} \\Psi_1^* \\hat{Q} \\Psi_2 = \\int \\mathop{dx} (\\hat{Q} \\Psi_1)^* \\Psi_2 \\quad (1.1) $$\n",
    "\n",
    "### We will sometimes use a briefer notation for the integrals of pairs of functions:\n",
    "## $$ \\boxed{\\langle \\Psi_1, \\Psi_2 \\rangle  \\equiv \\int \\mathop{dx} \\Psi_1^*(x) \\Psi_2(x)} \\quad (1.2) $$\n",
    "\n",
    "### Note that for any constant $a$\n",
    "### $$ \\langle a\\Psi_1, \\Psi_2 \\rangle  = a^*\\langle \\Psi_1, \\Psi_2\\rangle, \\quad \\langle\\Psi_1, a\\Psi_2\\rangle = a\\langle\\Psi_1, \\Psi_2\\rangle \\quad (1.3) $$\n",
    "\n",
    "### With this notation the condition of Hermiticity is more briefly stated\n",
    "## $$ \\hat{Q}\\, \\text{is Hermitian}: \\quad \\langle\\Psi_1, \\hat{Q}\\Psi_2\\rangle = \\langle\\hat{Q}\\Psi_1, \\Psi_2\\rangle\\quad (1.4) $$\n",
    "\n",
    "### The expectation value of $\\hat{Q}$ was defined by\n",
    "## $$ \\langle \\hat{Q} \\rangle_\\Psi = \\int \\mathop{dx}\\Psi^* \\hat{Q} \\Psi = \\langle\\Psi, \\hat{Q}\\Psi\\rangle \\quad (1.5) $$\n",
    "\n",
    "### For this formula to make sense, the state $\\Psi$ must be normalized.\n",
    "\n",
    "### **Claim 1**. \n",
    "### **The expectation value of a Hermitian operator is real**. \n",
    "\n",
    "### To prove this we complex conjugate the above definition. The complex conjugate of the integral is the integral of the complex conjugate of the integrand, therefore\n",
    "## $$ \\left(\\langle \\hat{Q} \\rangle_\\Psi\\right)^* = \\int \\mathop{dx} \\left(\\Psi^* \\hat{Q} \\Psi\\right)^* = \\int \\mathop{dx} \\Psi \\left(\\hat{Q} \\Psi\\right)^* = \\int \\mathop{dx} \\left(\\hat{Q} \\Psi\\right)^* \\Psi \\quad (1.6) $$\n",
    "\n",
    "### Note that $\\hat{Q}\\Psi$ is a wavefunction, so it makes sense to take its complex conjugate (we never have to think of conjugating $\\hat{Q}$). Using the Hermiticity of the operator, we move it into $\\Psi$ to get\n",
    "## $$ \\left(\\langle \\hat{Q} \\rangle_\\Psi\\right)^* = \\int \\mathop{dx} \\Psi^* \\hat{Q} \\Psi = \\langle \\hat{Q} \\rangle_\\Psi \\quad (1.7) $$\n",
    "\n",
    "### thus showing that the expectation value is indeed real.\n",
    "\n",
    "### **Claim 2**.\n",
    "### **The eigenvalues of a Hermitian operator are real**.\n",
    "\n",
    "### Assume the operator $\\hat{Q}$ has an eigenvalue $q_1$ associated with a normalized eigenfunction $\\psi_1(x)$:\n",
    "## $$ \\hat{Q} \\psi_1(x) = q_1 \\psi_1(x) \\quad (1.8) $$\n",
    "\n",
    "### Now compute the expectation value of $\\hat{Q}$ in the state $\\psi_1$:\n",
    "## $$ \\langle \\hat{Q} \\rangle_{\\psi_1} = \\langle\\psi_1, \\hat{Q} \\psi_1\\rangle = \\langle\\psi_1, q_1 \\psi_1\\rangle = q_1 \\langle\\psi_1, \\psi_1\\rangle = q_1 \\quad (1.9) $$\n",
    "\n",
    "### By claim 1, the expectation value is real, and so is the eigenvalue $q_1$, as we wanted to show. Note the interesting fact that the expectation value of $\\hat{Q}$ on an eigenstate is precisely given by the corresponding eigenvalue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b3c1f-ca59-4f1a-929a-148996b8f4b7",
   "metadata": {},
   "source": [
    "### Consider now the collection of eigenfunctions and eigenvalues of the Hermitian operator $\\hat{Q}$:\n",
    "## $$ \\begin{array} {rclr} \\hat{Q} \\psi_1(x) & = & q_1 \\psi_1(x) & \\quad (1.10) \\\\ \\hat{Q} \\psi_2(x) & = & q_2 \\psi_2 (x) & \\quad (1.11) \\\\ \\, & \\vdots & \\, & \\, \\end{array} $$\n",
    "\n",
    "### The list may be finite or infinite.\n",
    "\n",
    "### **Claim 3**.\n",
    "### **The eigenfunctions can be organized to satisfy orthonormality**:\n",
    "## $$ \\langle \\psi_i, \\psi_j \\rangle = \\int \\mathop{dx} \\psi_i^*(x) \\psi_j(x) = \\delta_{ij} \\quad (1.12) $$\n",
    "\n",
    "### For $i = j$, this is just a matter of normalizing properly each eigenfunction, which we can easily do. \n",
    "\n",
    "### The equation also states that different eigenfunctions are orthogonal, or have zero overlap. We now explain why this is so for $i \\neq j$ with $q_i \\neq q_j$. \n",
    "\n",
    "### Indeed, for this we evaluate $\\langle \\psi_i, \\hat{Q}\\psi_j \\rangle$ in two different ways. First\n",
    "## $$ \\langle \\psi_i, \\hat{Q} \\psi_j \\rangle = \\langle \\psi_i, q_j \\psi_j \\rangle = q_j \\langle \\psi_i, \\psi_j \\rangle \\quad (1.13) $$\n",
    "\n",
    "### and second, using Hermiticity of $\\hat{Q}$, and the reality of the eigenvalues\n",
    "## $$ \\langle \\psi_i, \\hat{Q} \\psi_j \\rangle = \\langle \\hat{Q} \\psi_i, \\psi_j \\rangle = \\langle q_i \\psi_i, \\psi_j \\rangle = q_i \\langle \\psi_i, \\psi_j \\rangle \\quad (1.14) $$\n",
    "\n",
    "### Equating the final right-hand sides in the two evaluations we get\n",
    "## $$ (q_i - q_j)\\langle \\psi_i, \\psi_j \\rangle = 0 \\quad (1.15) $$\n",
    "\n",
    "### Since the eigenvalues were assumed different, this proves that $\\langle \\psi_i, \\psi_j \\rangle = 0$, as claimed. This is not yet a full proof of $(1.12)$ because it is possible to have degeneracies in the spectrum, namely, different eigenfunctions with the same eigenvalue. In that case the above argument does not work. One must then show that it is possible to choose linear combinations of the degenerate eigenfunctions that are mutually orthogonal (the orthogonality with the eigenfunctions beyond the degenerate space is automatic). This is done in 8.05!\n",
    "\n",
    "### **Claim 4**.\n",
    "### **The orthonormal eigenfunctions of a Hermitian operator $\\hat{Q}$ form a complete set of basis functions: any reasonable $\\Psi$ can be written as a superposition of $\\hat{Q}$ eigenfunctions**. \n",
    "\n",
    "### (This is the so-called spectral theorem, which is proven in 8.05 in the finite-dimensional case.) \n",
    "\n",
    "### This means that\n",
    "## $$ \\boxed{\\Psi(x) = \\alpha_1 \\psi_1(x) + \\alpha_2 \\psi_2(x) + \\cdots = \\sum_{i}\\alpha_i \\psi_i(x)}\\quad (1.16) $$\n",
    "\n",
    "### with calculable coefficients $\\alpha_i$. Indeed, if we know the eigenfunctions we have that $\\alpha_i$ is calculated doing the integral of $\\psi_i^*$ against $\\Psi$:\n",
    "## $$ \\boxed{\\alpha_i = \\langle \\psi_i, \\Psi \\rangle} \\quad (1.17) $$\n",
    "\n",
    "### We quickly prove this by doing the integral\n",
    "## $$ \\int \\mathop{dx} \\psi_i^*(x) \\Psi(x) = \\int \\mathop{dx} \\psi_i^*(x) \\sum_j \\alpha_j \\psi_j(x) = \\sum_j \\alpha_j \\int \\mathop{dx} \\psi_i^*(x)\\psi_j(x) = \\sum_j \\alpha_j \\delta_{ij} = \\alpha_i \\quad (1.18) $$\n",
    "\n",
    "### The condition that $\\Psi$ is normalized implies a condition on the coefficients $\\alpha_i$. We have\n",
    "## $$ \\begin{array} {rcl} \\displaystyle \\int \\mathop{dx} \\Psi^*(x) \\Psi(x) & = & \\displaystyle \\mathop{dx} \\sum_i \\alpha_i^* \\psi_i^*(x) \\sum_j \\alpha_j \\psi_j (x) \\\\ \\, & = & \\displaystyle \\sum_{i,j} \\alpha_i^* \\alpha_j \\int \\mathop{dx} \\psi_i^*(x) \\psi_j(x) \\\\ \\, & = & \\displaystyle \\sum_{i,j} \\alpha_i^* \\alpha_j \\delta_{ij} \\\\ \\, & = & \\displaystyle \\sum_i \\alpha_i^* \\alpha_i \\end{array} \\quad (1.19) $$\n",
    "\n",
    "### so that the normalization of $\\Psi$ implies that\n",
    "## $$ \\sum_i |\\alpha_i|^2 = 1 \\quad (1.20) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095e956-620a-4162-880d-28a54203cf81",
   "metadata": {},
   "source": [
    "### We are finally in the position to state the measurement postulate. This is the way in which we understand that Hermitian operators represent observables and learn the rules that they follow.\n",
    "\n",
    "### **Measurement Postulate**:\n",
    "### If we measure the Hermitian operator $\\hat{Q}$ in the state $\\Psi$, the possible outcomes for the measurement are the eigenvalues $q_1, q_2, \\ldots$. The probability $p_i$ to measure $q_i$ is given by\n",
    "## $$ p_i = |\\alpha_i|^2 \\quad (1.21) $$\n",
    "\n",
    "### where $\\displaystyle \\Psi(x) = \\sum_{i} \\alpha_i \\psi_i(x)$. \n",
    "\n",
    "### After the outcome $q_i$, the state of the system becomes\n",
    "## $$ \\Psi(x) = \\psi_i(x) \\quad (1.22) $$\n",
    "\n",
    "### **This is called the collapse of the wavefunction**.\n",
    "\n",
    "### The collapse of the wavefunction implies that immediately after the measurement that yielded $q_i$ a repeated measurement of $\\hat{Q}$ will yield $q_i$ with no uncertainty. \n",
    "\n",
    "### A small subtlety occurs if we have degenerate eigenstates. Suppose the wavefunction contains a piece\n",
    "## $$ \\Psi = (\\alpha_i \\psi_i  + \\alpha_k \\psi_k) + \\cdots \\quad (1.23) $$\n",
    "\n",
    "### where $\\psi_i$ and $\\psi_k$ happen to have the same eigenvalue $q$ and the dots represent other terms. Then if we measure $q$ the state after the measurement collapses to the sum of those two terms\n",
    "## $$ \\Psi = \\frac{\\alpha_i \\psi_i + \\alpha_k \\psi_k}{\\sqrt{|\\alpha_i|^2+|\\alpha_k|^2}} \\quad (1.24) $$\n",
    "\n",
    "### with the square root denominator included to provide the proper normalization to $\\Psi$. \n",
    "\n",
    "### As a consistency check note that the probabilities $p_i$ to find the various eigenvalues as outcomes properly add to one:\n",
    "## $$ \\sum_i p_i = \\sum_i |\\alpha_i|^2 = 1 \\quad (1.25) $$\n",
    "\n",
    "### by the normalization condition for $\\Psi$ given in $(1.20)$. \n",
    "\n",
    "### The measurement postulate follows the **Copenhagen interpretation** of quantum mechanics.\n",
    "\n",
    "### Note that the measurement postulate uses the property that any vector in a vector space can be written as a sum of different vectors in an infinite number of ways. If we are to measure $\\hat{Q}_1$ we expand the state in $\\hat{Q}_1$ eigenstates, if we are to measure $\\hat{Q}_2$ we we expand the state in $\\hat{Q}_2$ eigenstates, and so on and so forth. Each decomposition is suitable for a particular measurement. Each decomposition reveals the various probabilities for the outcomes of the specific observable.\n",
    "\n",
    "### **Exercise**: \n",
    "### Use the expansion $\\displaystyle \\Psi = \\sum_i \\alpha_i \\psi_i$ to compute the expectation value $\\langle \\hat{Q} \\rangle$. \n",
    "\n",
    "### We find\n",
    "## $$ \\begin{array} {rcl} \\langle \\hat{Q} \\rangle & = & \\displaystyle \\int \\mathop{dx} \\sum_i \\alpha_i^* \\psi_i^*(x) \\hat{Q} \\sum_j \\alpha_j \\psi_j(x) \\\\ \\, & = & \\displaystyle \\sum_{i,j} \\alpha_i^* \\alpha_j \\int \\mathop{dx} \\psi_i^*(x) \\hat{Q} \\psi_j(x) \\\\ \\, & = & \\displaystyle \\sum_{i,j} \\alpha_i^* \\alpha_j q_j \\int \\mathop{dx} \\psi_i^*(x) \\psi_j(x) \\\\ \\, & = & \\displaystyle \\sum_{i,j} \\alpha_i^* \\alpha_j q_j \\delta_{ij} \\\\ \\, & = & \\displaystyle \\sum_i |\\alpha_i|^2 q_i \\\\ \\, & = & \\displaystyle \\sum_i p_i q_i \\end{array} \\quad (1.26) $$\n",
    "\n",
    "### This matches our expectations: the expectation value of $\\hat{Q}$ is the sum of the possible outcomes $q_i$ multiplied by the corresponding probabilities $p_i$. This is a nice consistency check on our definition of expectation values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5405b72a-bcf9-4530-8aa1-a8e05804df71",
   "metadata": {},
   "source": [
    "### **Example**.\n",
    "### Free particle on the circle $x \\in [0, L]$\n",
    "\n",
    "### We imagine the points $x = 0$ and $x = L$ identified to form a circle of circumference $L$. A wavefunction $\\Psi(x)$ on the circle must satisfy the periodicity condition\n",
    "## $$ \\Psi(x+L) = \\Psi(x) \\quad (1.27) $$\n",
    "\n",
    "### Assume that at some fixed time we have the wavefunction\n",
    "## $$ \\Psi(x) = \\sqrt{\\frac{2}{L}} \\left( \\frac{1}{\\sqrt{3}} \\sin \\left( \\frac{2\\pi x}{L} \\right) + \\sqrt{\\frac{2}{3}} \\cos \\left( \\frac{6\\pi x}{L} \\right) \\right) \\quad (1.28) $$\n",
    "\n",
    "### This wavefunction satisfies the periodicity condition, as you should check. We want to know what are the possible values of the momentum and their corresponding probabilities.\n",
    "\n",
    "### Given our discussion, we must find the set of momentum eigenstates and rewrite the wavefunction as a superposition of such states. Momentum eigenstates are exponentials of the form $e^{ikx}$. Two things happen on the circle that do not happen in free space. First the momentum will be quantized as a consequence of the periodicity condition $(1.27)$. Second, since space here is of finite length, the momentum wavefunctions will be normalizable. Consider the periodicity condition as applied to $e^{ikx}$. \n",
    "\n",
    "### We need\n",
    "## $$ e^{ikx} = e^{ik(x+L)} \\rightarrow e^{ikL} = 1 \\rightarrow kL = 2\\pi m, m\\in \\mathbb{Z} \\quad (1.29) $$\n",
    "\n",
    "### Note that $m$ can be any integer, positive, negative, or zero. We thus write for the momentum eigenstates, labeled by $m$\n",
    "## $$ \\psi_m(x) = N e^{\\frac{2\\pi i m x}{L}} \\quad(1.30) $$\n",
    "\n",
    "### with $N$ a real normalization constant. The normalization condition gives\n",
    "## $$ 1 = \\int_0^L |\\psi_m(x)|^2 \\mathop{dx} = N^2 \\int_0^L \\mathop{dx}  = N^2 L \\rightarrow N = \\frac{1}{\\sqrt{L}} \\quad (1.31) $$\n",
    "\n",
    "### Therefore our momentum eigenstates are\n",
    "## $$ \\psi_m(x) = \\frac{1}{\\sqrt{L}} e^{\\frac{2\\pi i m x}{L}} \\quad (1.32) $$\n",
    "\n",
    "### and these are states with momentum $p_m$, which is calculated as follows\n",
    "## $$ \\hat{p} \\psi_m = \\frac{\\hbar}{i} \\frac{\\partial}{\\partial x} \\psi_m = \\frac{2\\pi m \\hbar}{L} \\psi_m \\rightarrow p_m = \\frac{2\\pi m \\hbar}{L} \\quad (1.33) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5240b072-06c6-430f-92cb-afa19a3f416b",
   "metadata": {},
   "source": [
    "### Now that we are equipped with the momentum eigenstates we must simply rewrite the wavefunction $(1.28)$ as a superposition of such states:\n",
    "## $$ \\Psi(x) = \\sqrt{\\frac{2}{3}} \\frac{1}{2i} \\frac{1}{\\sqrt{L}}\\left( e^{\\frac{2\\pi i x}{L}}-e^{-\\frac{2\\pi i x}{L}} \\right) + \\frac{2}{\\sqrt{3}}\\frac{1}{2} \\frac{1}{\\sqrt{L}} \\left( e^{\\frac{6\\pi i x}{L}} + e^{-\\frac{6\\pi i x}{L}} \\right) \\quad (1.34) $$\n",
    "\n",
    "### We then recognize that we have\n",
    "## $$ \\Psi(x) = \\sqrt{\\frac{2}{3}} \\frac{1}{2i} \\psi_1(x) - \\sqrt{\\frac{2}{3}} \\frac{1}{2i}\\psi_{-1}(x) + \\frac{1}{\\sqrt{3}} \\psi_3(x) + \\frac{1}{\\sqrt{3}} \\psi_{-3}(x) \\quad (1.35) $$\n",
    "\n",
    "### This is our key result: the original wavefunction written as a superposition of momentum eigenstates $\\psi_m(x)$. We can now give the possible values $p$ of the momentum and their corresponding probabilities $P$:\n",
    "## $$ \\begin{array} {rclrcccl} p & = & \\displaystyle \\frac{2\\pi \\hbar}{L}, & P & = & \\displaystyle \\left| \\sqrt{\\frac{2}{3}} \\frac{1}{2i} \\right|^2 & = & \\displaystyle \\frac{1}{6} \\\\ p & = & \\displaystyle -\\frac{2\\pi \\hbar}{L}, & P & = & \\displaystyle \\left| -\\sqrt{\\frac{2}{3}} \\frac{1}{2i} \\right|^2 & = & \\displaystyle \\frac{1}{6} \\\\ p & = & \\displaystyle \\frac{6\\pi \\hbar}{L}, & P & = & \\displaystyle \\left| \\sqrt{\\frac{1}{3}} \\right|^2 & = & \\displaystyle \\frac{1}{3} \\\\ p & = & \\displaystyle -\\frac{6\\pi \\hbar}{L}, & P & = & \\displaystyle \\left| \\sqrt{\\frac{1}{3}} \\right|^2 & = & \\displaystyle \\frac{1}{3} \\end{array} \\quad (1.36) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8327bf25-8619-48cc-8c49-df25f2f4292a",
   "metadata": {},
   "source": [
    "## 9.2 Uncertainty\n",
    "\n",
    "### For random variables, the uncertainty is the **standard deviation** — the square root of the expected value of the square of deviations from the average value. \n",
    "\n",
    "### Let $Q$ be a random variable that takes on values $Q_1, \\ldots, Q_n$ with probabilities $p_1, \\ldots, p_n$, respectively. The expected value is\n",
    "## $$ \\langle Q \\rangle = \\overline{Q} = \\sum_i p_i Q_i \\quad (2.37) $$\n",
    "\n",
    "### and the variance (the square of the standard deviation) is\n",
    "## $$ (\\Delta Q)^2 \\equiv \\sum_i p_i(Q_i - \\overline{Q})^2 \\quad (2.38) $$\n",
    "\n",
    "### This definition makes it clear that if $\\Delta Q = 0$, then the random variable is constant: each term in the above sum must vanish, making $Q_i = \\overline{Q}$, for all $i$. \n",
    "\n",
    "### We find another useful expression by expanding the above definition\n",
    "## $$ \\begin{array} {rcl} (\\Delta Q)^2 & = & \\displaystyle \\sum_i p_i Q_i^2 - 2\\sum_i p_i Q_i \\overline{Q} + \\sum_i p_i \\overline{Q}^2 \\\\ \\, & = & \\displaystyle \\overline{Q^2} - 2 \\overline{Q} \\overline{Q} + \\overline{Q}^2 = \\overline{Q^2}-\\overline{Q}^2 \\end{array} \\quad (2.39) $$\n",
    "\n",
    "### where we used $\\displaystyle \\sum_i p_i = 1$. \n",
    "\n",
    "### Therefore\n",
    "## $$ (\\Delta Q)^2 = \\overline{Q^2}-\\overline{Q}^2 \\quad (2.40) $$\n",
    "\n",
    "### Since, by definition $(\\Delta Q)^2 \\geq 0$, we have the interesting inequality\n",
    "## $$ \\overline{Q^2} \\geq \\overline{Q}^2 \\quad (2.41) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aef030-8b42-44bb-af30-02dfd8cb6e7f",
   "metadata": {},
   "source": [
    "### Now let us consider the quantum mechanical case. We have already defined expectation values of Hermitian operators, so we can now mimic the definition $(2.40)$ and declare that the uncertainty $\\Delta \\hat{Q}_\\Psi$ of an operator in a state $\\Psi$ is a real number whose square is given by\n",
    "## $$ (\\Delta \\hat{Q})_\\Psi^2 = \\langle \\hat{Q}^2 \\rangle_\\Psi - (\\langle \\hat{Q} \\rangle_\\Psi)^2 \\quad (2.42) $$\n",
    "\n",
    "### Sometimes for brevity, we omit the label for the state,\n",
    "## $$ \\boxed{(\\Delta\\hat{Q})^2 = \\langle \\hat{Q}^2 \\rangle - \\langle \\hat{Q} \\rangle^2} \\quad (2.43) $$\n",
    "\n",
    "### **Claim 1**. \n",
    "### The uncertainty can also be written as the expectation value of the square of the difference between the operator and its expectation value:\n",
    "## $$ (\\Delta \\hat{Q})^2 = \\left\\langle \\left(\\hat{Q}-\\langle \\hat{Q} \\rangle\\right)^2 \\right\\rangle \\quad (2.44) $$\n",
    "\n",
    "### Indeed, expanding the right hand side we have\n",
    "## $$ \\left\\langle \\hat{Q}^2 - 2\\hat{Q} \\langle \\hat{Q} \\rangle +\\langle \\hat{Q} \\rangle^2 \\right\\rangle = \\langle \\hat{Q}^2 \\rangle - 2 \\langle \\hat{Q} \\rangle \\langle \\hat{Q} \\rangle + \\langle \\hat{Q} \\rangle^2 \\quad (2.45) $$\n",
    "\n",
    "### **Claim 2**.\n",
    "### The uncertainty can be written as the integral of the square of the norm of $(\\hat{Q}-\\langle \\hat{Q} \\rangle )\\Psi$:\n",
    "## $$ (\\Delta \\hat{Q})^2 = \\int_{-\\infty}^{\\infty} \\mathop{dx} \\left| \\left( \\hat{Q} - \\langle \\hat{Q} \\rangle \\right)\\Psi(x) \\right|^2 \\quad (2.46) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d2ed07-cac3-406c-8024-97c2566cb8d1",
   "metadata": {},
   "source": [
    "### Indeed to prove this we begin with $(2.44)$ \n",
    "### By a very similar proof, we can show this is equivalent to \n",
    "## $$ (\\Delta \\hat{Q})^2 = \\left\\langle \\left( \\hat{Q} - \\langle \\hat{Q} \\rangle \\right)^2 \\right\\rangle = \\int \\mathop{dx} \\Psi^* \\left( \\hat{Q} - \\langle \\hat{Q} \\rangle \\right)^2 \\Psi \\quad (2.47) $$\n",
    "\n",
    "### Using the Hermiticity of $\\hat{Q}$ and the reality of $\\langle \\hat{Q} \\rangle$ we can bring one of the two factors to act on $\\Psi^*$:\n",
    "## $$ (\\Delta \\hat{Q})^2 = \\int \\mathop{dx} \\left[ \\left( \\hat{Q} - \\langle \\hat{Q} \\rangle \\right) \\Psi \\right]^* \\left( \\hat{Q} - \\langle \\hat{Q} \\rangle \\right) \\Psi = \\int \\mathop{dx} \\left| \\left( \\hat{Q} - \\langle \\hat{Q} \\rangle  \\right) \\Psi \\right|^2 \\quad (2.48) $$\n",
    "\n",
    "### This completes the proof of claim 2.\n",
    "\n",
    "### If $\\Delta \\hat{Q} = 0$, then by claim 2, we must have that for all $x$:\n",
    "## $$ \\left( \\hat{Q} - \\langle \\hat{Q} \\rangle \\right) \\Psi(x) = 0 \\rightarrow \\hat{Q} \\Psi(x) = \\langle \\hat{Q} \\rangle \\Psi(x) \\quad (2.49) $$\n",
    "\n",
    "### We see that $\\Psi$ is an eigenstate of $\\hat{Q}$, which indeed means there is no uncertainty in the measurement. Of course if $\\Psi$ is an eigenstate of $\\hat{Q}$ then again $\\hat{Q} \\Psi = \\langle \\hat{Q} \\rangle \\Psi$ and the uncertainty vanishes. All in all, we have established the equivalence\n",
    "## $$ \\boxed{\\Delta \\hat{Q}_\\Psi = 0 \\iff \\Psi \\, \\text{is an eigenstate of}\\, \\hat{Q}} \\quad (2.50) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398ddb3-768b-40ef-b33d-de607b1a95a1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
